{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "school_NN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "yC4JzkuKBEyo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* **If smth fails, try resetting session/terminating!**\n",
        "\n",
        "* **Executing consequently 1,2,3 and restarting works**"
      ]
    },
    {
      "metadata": {
        "id": "W1vqpeNzT-DJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plans & Ideas\n",
        "* use a part of the data\n",
        "* sPlot weights as a new feature\n",
        "  * doesn't make any sense in search for an unlnown signal, but might be useful in reducing bkgr\n",
        "* uniformity over bkgr\n",
        "  * handmade losses to prevent similarities between sig and bkgr mass distribution\n",
        "  * checking it with tests\n",
        "* weighted AUC\n",
        "* Focal Loss - https://arxiv.org/abs/1708.02002\n",
        "* something from tau->3mu\n",
        "* play with nB (does it affect smth?)\n",
        "* calibration\n",
        "* dR antimatching as bkgr samples\n"
      ]
    },
    {
      "metadata": {
        "id": "VAE-HjN2yRE9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **pip libraries**"
      ]
    },
    {
      "metadata": {
        "id": "lLn6DKh1sfob",
        "colab_type": "code",
        "outputId": "ec16c172-7fd4-4e53-d0b5-6b83feb6516d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aV67Wch5ugx4",
        "colab_type": "code",
        "outputId": "ba83d893-7003-4bae-9dbe-704e549cc836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1161
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install numpy -U\n",
        "!pip install pandas -U\n",
        "!pip install seaborn -U\n",
        "!pip install lightgbm -U"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/bf/4981bcbee43934f0adb8f764a1e70ab0ee5a448f6505bd04a87a2fda2a8b/numpy-1.16.1-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 17.3MB 2.3MB/s \n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mthinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mpymc3 3.6 has requirement joblib<0.13.0, but you'll have joblib 0.13.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "Successfully installed numpy-1.16.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/de/a0d3defd8f338eaf53ef716e40ef6d6c277c35d50e09b586e170169cdf0d/pandas-0.24.1-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 10.1MB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.16.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
            "\u001b[31mpymc3 3.6 has requirement joblib<0.13.0, but you'll have joblib 0.13.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 0.22.0\n",
            "    Uninstalling pandas-0.22.0:\n",
            "      Successfully uninstalled pandas-0.22.0\n",
            "Successfully installed pandas-0.24.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting seaborn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)\n",
            "\r\u001b[K    4% |█▋                              | 10kB 18.4MB/s eta 0:00:01\r\u001b[K    9% |███▏                            | 20kB 3.2MB/s eta 0:00:01\r\u001b[K    14% |████▊                           | 30kB 4.6MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 40kB 3.0MB/s eta 0:00:01\r\u001b[K    24% |███████▉                        | 51kB 3.7MB/s eta 0:00:01\r\u001b[K    29% |█████████▌                      | 61kB 4.4MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 71kB 5.0MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 81kB 5.7MB/s eta 0:00:01\r\u001b[K    44% |██████████████▏                 | 92kB 6.3MB/s eta 0:00:01\r\u001b[K    49% |███████████████▊                | 102kB 4.9MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▎              | 112kB 5.0MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 122kB 6.9MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▌           | 133kB 6.9MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 143kB 12.6MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 153kB 12.7MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 163kB 12.6MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▊     | 174kB 12.4MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▍   | 184kB 12.5MB/s eta 0:00:01\r\u001b[K    93% |██████████████████████████████  | 194kB 12.5MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 204kB 40.1MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 215kB 27.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (0.24.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.16.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.15.2->seaborn) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (40.8.0)\n",
            "Installing collected packages: seaborn\n",
            "  Found existing installation: seaborn 0.7.1\n",
            "    Uninstalling seaborn-0.7.1:\n",
            "      Successfully uninstalled seaborn-0.7.1\n",
            "Successfully installed seaborn-0.9.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "seaborn"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.20.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.16.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EP5CCDjmhWzm",
        "colab_type": "code",
        "outputId": "d98420f3-1c69-4d16-d355-fb4241201584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1224
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install shap -U\n",
        "!pip install gpyopt\n",
        "!pip install sobol_seq\n",
        "# !pip install hep_ml -U"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting shap\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/b3/866b0101cbd1829844c35964af68c14ba522a5cce7a1e8d0f7937411d910/shap-0.28.5.tar.gz (223kB)\n",
            "\u001b[K    100% |████████████████████████████████| 225kB 12.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from shap) (1.16.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from shap) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from shap) (0.20.2)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from shap) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from shap) (0.24.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from shap) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: ipython in /usr/local/lib/python3.6/dist-packages (from shap) (5.5.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image in /usr/local/lib/python3.6/dist-packages (from shap) (0.13.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->shap) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->shap) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->shap) (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->shap) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->shap) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->shap) (40.8.0)\n",
            "Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->shap) (0.7.5)\n",
            "Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->shap) (2.1.3)\n",
            "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->shap) (1.0.15)\n",
            "Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->shap) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->shap) (4.6.0)\n",
            "Requirement already satisfied, skipping upgrade: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->shap) (4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->shap) (4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.7.3 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap) (2.2)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->shap) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->shap) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->shap) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=2.1.0->scikit-image->shap) (0.46)\n",
            "Building wheels for collected packages: shap\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/bf/26/bd/912db1314f1cef0171d9b7f128dd01e8b8c92ed8d0062e632d\n",
            "Successfully built shap\n",
            "Installing collected packages: shap\n",
            "Successfully installed shap-0.28.5\n",
            "Collecting gpyopt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/40/ca8f080d74d9f4e29069faa944fcfb083e8693b6daaba0f1e4bc65c88650/GPyOpt-1.2.5.tar.gz (55kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from gpyopt) (1.16.1)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.6/dist-packages (from gpyopt) (1.1.0)\n",
            "Collecting GPy>=1.8 (from gpyopt)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/7d/e55ffc3b16b68e8b50ccecacec56715bcf49d5c2f204f5ba60374d419611/GPy-1.9.6.tar.gz (873kB)\n",
            "\u001b[K    100% |████████████████████████████████| 880kB 22.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from GPy>=1.8->gpyopt) (1.11.0)\n",
            "Collecting paramz>=0.9.0 (from GPy>=1.8->gpyopt)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/78/b0f0164a32518bfd3b98cb2e149b7a4d5504d13fb503b31a6c59b958ed18/paramz-0.9.4.tar.gz (70kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 21.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.6/dist-packages (from paramz>=0.9.0->GPy>=1.8->gpyopt) (4.3.2)\n",
            "Building wheels for collected packages: gpyopt, GPy, paramz\n",
            "  Building wheel for gpyopt (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/33/1d/87/dc02440831ba986b1547dd11a7dcd44e893b0527083066d869\n",
            "  Building wheel for GPy (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/97/82/1d/32a361e1ff2b4d9129a60343831dd99cdc74440e2db1c55264\n",
            "  Building wheel for paramz (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a9/fc/74/3bbd263c43ed98d67343df24cebf0a0ee34afee40d769fda9c\n",
            "Successfully built gpyopt GPy paramz\n",
            "Installing collected packages: paramz, GPy, gpyopt\n",
            "Successfully installed GPy-1.9.6 gpyopt-1.2.5 paramz-0.9.4\n",
            "Collecting sobol_seq\n",
            "  Downloading https://files.pythonhosted.org/packages/89/7a/7b374fd1f100bfea2624190f3dd879029e1aabe70d34e279ef456d522717/sobol_seq-0.1.2.zip\n",
            "Building wheels for collected packages: sobol-seq\n",
            "  Building wheel for sobol-seq (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d5/72/1f/6cd8a0b472da802ee9c84fdc39626bb4ec544668c030917d9f\n",
            "Successfully built sobol-seq\n",
            "Installing collected packages: sobol-seq\n",
            "Successfully installed sobol-seq-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E3No6I-F29vi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### pytorch"
      ]
    },
    {
      "metadata": {
        "id": "rI1QInUdzTBQ",
        "colab_type": "code",
        "outputId": "64e466e1-62e2-49ac-95b6-088a967d0b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# from os import path\n",
        "# from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "# platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "# accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "# !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "# import torch\n",
        "# print(torch.__version__)\n",
        "# print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 484.0MB 34.8MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 11.2MB/s \n",
            "\u001b[31mfastai 1.0.43 has requirement torch>=1.0.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "\u001b[?25h0.4.0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A-YAEIucz3fy",
        "colab_type": "code",
        "outputId": "901bc40a-fa02-4405-bb77-4186179b11a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "cell_type": "code",
      "source": [
        "# from pytorch install webpage\n",
        "\n",
        "!pip install https://download.pytorch.org/whl/cu80/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl\n",
        "!pip install torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.0.1.post2 from https://download.pytorch.org/whl/cu80/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.0.1.post2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.1.post2)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.1)\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.0.1.post2\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jm8kWtoLopG4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ]
    },
    {
      "metadata": {
        "id": "O-wV9_Akx2WS",
        "colab_type": "code",
        "outputId": "af62355d-427c-4623-aed1-4c230fb1e5fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# import graphviz\n",
        "import itertools\n",
        "\n",
        "from IPython.display import Image        \n",
        "\n",
        "from sklearn.model_selection import learning_curve, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import linear_model, tree, ensemble\n",
        "from sklearn.preprocessing import scale, StandardScaler, PolynomialFeatures\n",
        "from sklearn import utils\n",
        "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, RandomizedSearchCV\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.feature_selection import SelectFromModel, RFE\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2, mutual_info_classif, f_classif\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import roc_auc_score, auc, classification_report, matthews_corrcoef, log_loss\n",
        "\n",
        "import lightgbm as lgb\n",
        "# import shap\n",
        "\n",
        "# from hep_ml import uboost, gradientboosting as ugb, losses\n",
        "\n",
        "# import pyDOE\n",
        "%pylab inline  \n",
        "\n",
        "sns.__version__\n",
        "\n",
        "\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data.dataset import Subset\n",
        "\n",
        "# from ignite.contrib.handlers import ProgressBar\n",
        "# from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
        "# from ignite.handlers import ModelCheckpoint, Timer, EarlyStopping\n",
        "# from ignite.metrics import RunningAverage, Accuracy, Loss\n",
        "# from ignite.contrib.handlers.param_scheduler import LinearCyclicalScheduler, CosineAnnealingScheduler \n",
        "\n",
        "# import visdom \n",
        "\n",
        "import GPy\n",
        "import GPyOpt\n",
        "from GPyOpt.methods import BayesianOptimization\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# !pip install livelossplot\n",
        "# from livelossplot import PlotLosses\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.is_available())\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n",
            "True\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "b983c773-8b54-46a8-fa09-7a2cc0e04e5a",
        "id": "DEAdnTo6xDLi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/test')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OncBhbMSy0Rm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **Getting data**"
      ]
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "id": "yuywHXszx2Wb",
        "colab_type": "code",
        "outputId": "2dcc3e0e-2d67-4fae-93fb-ecc76ab234dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "MC   = pd.read_pickle('MC_pair_dR_psi_renamed.pkl')\n",
        "# data    = pd.read_pickle('data_B0_e3de87.pkl')\n",
        "data    = pd.read_pickle('data_B0_e3de87_nB_4000.pkl')\n",
        "data = data.set_index([pd.Series(range(data.shape[0]))]) # removing str labels\n",
        "\n",
        "MC_vars = [\"dR_mu1\", \"dR_mu2\", \"dR_pi1\", \"dR_pi2\", \"dR_K1\", \"dR_K2\",\n",
        "           \"dR_mu1_vv\", \"dR_mu2_vv\", \"dR_pi1_vv\", \"dR_pi2_vv\", \"dR_K1_vv\", \"dR_K2_vv\",\n",
        "           'gen_phi_mass', 'delta_phi_mass',\n",
        "           \"BU_reflmass1_Cjp\", \"BU_reflmass2_Cjp\"] \n",
        "\n",
        "MC.shape, data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((230149, 50), (183406, 34))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "id": "OhtCNopQx2We",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dR_match = 0.01\n",
        "matching_mask = ((MC[['dR_mu1', 'dR_mu1_vv']].min(axis=1) < dR_match) & (MC[['dR_mu2', 'dR_mu2_vv']].min(axis=1) < dR_match) & (MC[['dR_pi1', 'dR_pi1_vv']].min(axis=1) < dR_match) &\n",
        "                 (MC[['dR_pi2', 'dR_pi2_vv']].min(axis=1) < dR_match) & (MC[['dR_K1', 'dR_K1_vv']].min(axis=1) < dR_match) & (MC[['dR_K2', 'dR_K2_vv']].min(axis=1) < dR_match))\n",
        "signal = MC[matching_mask]\n",
        "\n",
        "#---#\n",
        "B_window = 0.05; #left_sdbd_dist = 5.366 - 5.25 - B_window\n",
        "mass_mask_for_bkgr = np.array([True] * data.shape[0])\n",
        "mass_mask_for_sig = np.array([True] * signal.shape[0])\n",
        "sig_window = {'BU_mass_Cjp': [5.366 - B_window, 5.366 + B_window]}\n",
        "\n",
        "for key, value in sig_window.items():\n",
        "    mass_mask_for_bkgr &= ((data[key] > value[0] - B_window) & (data[key] < value[0])) | ( (data[key] > value[1]) & (data[key] < value[1] + B_window))\n",
        "    mass_mask_for_sig &= (signal[key] > value[0]) & (signal[key] < value[1])\n",
        "\n",
        "bkgr = data[mass_mask_for_bkgr]\n",
        "signal = signal[mass_mask_for_sig]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "meApv4YLgYMQ",
        "colab_type": "code",
        "outputId": "8177c446-bd8a-4a0c-c9ff-6b45745479fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "signal.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84553, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "id": "g3DoTLGwx2Wi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **Define final dataframe for training**"
      ]
    },
    {
      "metadata": {
        "id": "S_iH11T060CV",
        "colab_type": "code",
        "outputId": "6ab43502-7845-4468-8f0b-853a42819752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['psi_eta', 'BU_pvdistsignif2_Cjp', 'mu_1_pt', 'PI2_eta', 'BU_pt_Cjp',\n",
              "       'K1_pt', 'BU_vtxprob_Cjp', 'mu_2_eta', 'phi_eta', 'BU_mass_Cjp',\n",
              "       'phi_pt', 'BU_pvdistsignif3_Cjp', 'nB', 'mu_2_pt', 'JP_pt',\n",
              "       'JPSI_pvcos2_Cmumu', 'K2_eta', 'JPSI_vtxprob_Cmumu', 'K2_pt',\n",
              "       'JPSI_pvdistsignif2_Cmumu', 'JPSI_mass_Cmumu', 'psi_pt', 'PI2_pt',\n",
              "       'BU_eta_Cjp', 'PHI_mass_Cjp', 'psi_mass_Cjp', 'mu_1_eta', 'K1_eta',\n",
              "       'BU_pvcos2_Cjp', 'PI1_pt', 'PI1_eta', 'PV_bestBang_RF_CL', 'JP_eta',\n",
              "       'PIPI_mass_Cjp'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "SQHRtEZtx2Wj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "drop_vars = [] # ['nB']\n",
        "drop_masses = ['BU_mass_Cjp', 'PHI_mass_Cjp', 'psi_mass_Cjp', 'PIPI_mass_Cjp'] # , 'PHI_mass_Cjp', 'psi_mass_Cjp', 'PIPI_mass_Cjp'\n",
        "\n",
        "\n",
        "signal = signal.drop(drop_vars + MC_vars, axis=1, inplace=False)\n",
        "bkgr = bkgr.drop(drop_vars, axis=1, inplace=False)[signal.columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "89CH_o5Ox2Wn",
        "colab_type": "code",
        "outputId": "94e86ca4-4472-41fd-c7d7-753e05382fcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(f'Signal shape: {signal.shape[0]}\\nBkgr shape: {bkgr.shape[0]}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Signal shape: 84553\n",
            "Bkgr shape: 37229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HpJ4Tio2x2Wr",
        "colab_type": "code",
        "outputId": "989e662a-cb33-4170-b28b-ae534233d432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "min_shape = min(bkgr.shape[0], signal.shape[0])\n",
        "\n",
        "bkgr = utils.shuffle(bkgr, random_state=123)[:min_shape] \n",
        "signal = utils.shuffle(signal, random_state=123)[:min_shape] \n",
        "\n",
        "### make target labels and append sig with bkgr\n",
        "bkgr['target'] = [0]*bkgr.shape[0]\n",
        "signal['target'] = [1]*signal.shape[0]\n",
        "df = bkgr.append(signal)\n",
        "\n",
        "\n",
        "print('Sig/bkgr shapes:', signal.shape, bkgr.shape)\n",
        "print('Dataframe shape:', df.shape)\n",
        "# print('\\nNow better')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sig/bkgr shapes: (37229, 35) (37229, 35)\n",
            "Dataframe shape: (74458, 35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FQvsF2RCx2Ww",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ### **Drop nan, shuffle and split into X (features) and y (targets)**"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "Are2SWFlx2Wx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print ('Nan indices:\\n ', np.argwhere(np.isnan(df.values)), '\\n', sum(np.isnan(df.values)))\n",
        "df = df.dropna(inplace=False) \n",
        "\n",
        "df = utils.shuffle(df, random_state=123)\n",
        "X = df.iloc[:, :-1]\n",
        "y = df['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NaBhbeOVx2W1",
        "colab_type": "code",
        "outputId": "32fe5ba5-1cb1-4af0-bb69-863144ca1b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(f'NaNs in features:\\n{df.columns[3]}, {df.columns[17]}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NaNs in features:\n",
            "psi_pt, K2_eta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WWD1VHVUx2W6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **Train / Test split**"
      ]
    },
    {
      "metadata": {
        "id": "vDXkWaPDx2W-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(X_traval, X_test, y_traval, y_test) = train_test_split(X, y,\n",
        "                                     test_size=0.2, \n",
        "                                     random_state=123, stratify=y)\n",
        "\n",
        "(X_train, X_val, y_train, y_val) = train_test_split(X_traval, y_traval,\n",
        "                                     test_size=0.25, \n",
        "                                     random_state=123, stratify=y_traval)\n",
        "\n",
        "train_masses = X_train[['BU_mass_Cjp', 'PHI_mass_Cjp', 'psi_mass_Cjp']]\n",
        "X_train = X_train.drop(columns=drop_masses)\n",
        "\n",
        "test_masses = X_test[['BU_mass_Cjp', 'PHI_mass_Cjp', 'psi_mass_Cjp']]\n",
        "X_test = X_test.drop(columns=drop_masses)\n",
        "\n",
        "val_masses = X_val[['BU_mass_Cjp', 'PHI_mass_Cjp', 'psi_mass_Cjp']]\n",
        "X_val = X_val.drop(columns=drop_masses)\n",
        "\n",
        "X_train = np.array(X_train, dtype='float64')\n",
        "X_test = np.array(X_test, dtype='float64')\n",
        "X_val = np.array(X_val, dtype='float64')\n",
        "\n",
        "y_train = np.array(y_train, dtype='int')\n",
        "y_test = np.array(y_test, dtype='int')\n",
        "y_val = np.array(y_val, dtype='int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ukQEljLFx2XC",
        "colab_type": "code",
        "outputId": "d6715dfa-4d89-4c59-ebf9-f7d5af9144bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "X_val[5]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([57.47633934,  6.17794593,  1.40427627, 13.74554346, 16.62144523,\n",
              "        1.6534085 ,  0.1413883 ,  1.60210319,  1.34260039,  2.88873946,\n",
              "       72.57888096,  2.        ,  5.15920458, 11.0359782 ,  0.99999941,\n",
              "        1.38260844,  0.46248439,  1.25063112,  1.712655  , 49.42395924,\n",
              "        3.06640172,  0.80747311,  1.69399854,  1.64124031,  1.74080783,\n",
              "        1.30480812,  0.99995016,  1.92535807,  1.69050186,  0.99352568])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "K2SxkRD80xxo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **LightGBM**"
      ]
    },
    {
      "metadata": {
        "id": "CVM4P91bpyHl",
        "colab_type": "code",
        "outputId": "c036dfe2-71bb-464c-96ac-5f04524d6fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.columns"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2625f76b8a6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "BOGQ-7NB0-wU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = lgb.Dataset(X_train, label=y_train)\n",
        "test_data  = lgb.Dataset(X_test, label=y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l4aTnsYw00WG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lgb_params = {'seed': 123, 'device': 'cpu',\n",
        "           'num_leaves': 30, 'max_depth': 10, 'subsample': .8, 'colsample_bytree': .8,\n",
        "           'learning_rate': 0.01,  'lambda': 0,'min_child_weight': 1\n",
        "               }\n",
        "\n",
        "lgb_params['metric'] = ['auc', 'binary_logloss']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tFGYfz9F2Bd-",
        "colab_type": "code",
        "outputId": "53907418-4312-487c-df32-2c8e75096de5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "cell_type": "code",
      "source": [
        "num_round = 999\n",
        "bst = lgb.train(lgb_params, train_data, num_round, early_stopping_rounds=10, valid_sets=[test_data], verbose_eval=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[20]\tvalid_0's binary_logloss: 0.586872\tvalid_0's auc: 0.957979\n",
            "[40]\tvalid_0's binary_logloss: 0.508467\tvalid_0's auc: 0.959496\n",
            "[60]\tvalid_0's binary_logloss: 0.45318\tvalid_0's auc: 0.960919\n",
            "[80]\tvalid_0's binary_logloss: 0.409076\tvalid_0's auc: 0.962109\n",
            "[100]\tvalid_0's binary_logloss: 0.375077\tvalid_0's auc: 0.96286\n",
            "[120]\tvalid_0's binary_logloss: 0.347287\tvalid_0's auc: 0.963599\n",
            "[140]\tvalid_0's binary_logloss: 0.324355\tvalid_0's auc: 0.964303\n",
            "[160]\tvalid_0's binary_logloss: 0.307485\tvalid_0's auc: 0.964964\n",
            "[180]\tvalid_0's binary_logloss: 0.29214\tvalid_0's auc: 0.965724\n",
            "[200]\tvalid_0's binary_logloss: 0.279714\tvalid_0's auc: 0.966312\n",
            "[220]\tvalid_0's binary_logloss: 0.269029\tvalid_0's auc: 0.966957\n",
            "[240]\tvalid_0's binary_logloss: 0.259595\tvalid_0's auc: 0.967591\n",
            "[260]\tvalid_0's binary_logloss: 0.251349\tvalid_0's auc: 0.968188\n",
            "[280]\tvalid_0's binary_logloss: 0.244767\tvalid_0's auc: 0.968694\n",
            "[300]\tvalid_0's binary_logloss: 0.239371\tvalid_0's auc: 0.969175\n",
            "[320]\tvalid_0's binary_logloss: 0.234783\tvalid_0's auc: 0.969598\n",
            "[340]\tvalid_0's binary_logloss: 0.23078\tvalid_0's auc: 0.970009\n",
            "Early stopping, best iteration is:\n",
            "[346]\tvalid_0's binary_logloss: 0.22974\tvalid_0's auc: 0.970122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3gc54VAkPb-C",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_test = bst.predict(X_test)\n",
        "prediction_train = bst.predict(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gQYzJJmPyZz5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### pytorch net"
      ]
    },
    {
      "metadata": {
        "id": "8NcTk9zNn1nV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_in = X_train.shape[1]\n",
        "n_out = np.unique(y_train).shape[0]\n",
        "n_hidden = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k__hcqQSn1nb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        m.bias.data.fill_(0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "WMlvRUOcn1ng",
        "colab_type": "code",
        "outputId": "daeb6324-5764-49a3-d634-45d5cf898368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "cell_type": "code",
      "source": [
        "model = nn.Sequential()\n",
        "\n",
        "# dense \"head\"\n",
        "model.add_module('batch0', nn.BatchNorm1d(n_in))\n",
        "model.add_module('dense1', nn.Linear(n_in, n_hidden))\n",
        "model.add_module('batch1', nn.BatchNorm1d(n_hidden))\n",
        "# model.add_module('do1', nn.Dropout(p=0.5))\n",
        "model.add_module('dense1_relu', nn.ReLU())\n",
        "                 \n",
        "model.add_module('dense2', nn.Linear(n_hidden, n_hidden))\n",
        "model.add_module('batch2', nn.BatchNorm1d(n_hidden))\n",
        "# model.add_module('do2', nn.Dropout(p=0.5))\n",
        "model.add_module('dense2_relu', nn.ReLU())\n",
        "                 \n",
        "# model.add_module('dense3', nn.Linear(n_hidden, n_hidden))\n",
        "# model.add_module('batch3', nn.BatchNorm1d(n_hidden))\n",
        "# # model.add_module('do3', nn.Dropout(p=0.5))\n",
        "# model.add_module('dense3_relu', nn.ReLU())\n",
        "\n",
        "# model.add_module('dense4', nn.Linear(n_hidden, n_hidden))\n",
        "# model.add_module('batch4', nn.BatchNorm1d(n_hidden))\n",
        "# # model.add_module('do4', nn.Dropout(p=0.5))\n",
        "# model.add_module('dense4_relu', nn.ReLU())\n",
        "\n",
        "# model.add_module('dense5', nn.Linear(n_hidden, n_hidden))\n",
        "# model.add_module('batch5', nn.BatchNorm1d(n_hidden))\n",
        "# model.add_module('do5', nn.Dropout(p=0.5))\n",
        "# model.add_module('dense5_relu', nn.ReLU())\n",
        "\n",
        "# model.add_module('dense4', nn.Linear(n_hidden, n_hidden))\n",
        "# model.add_module('batch4', nn.BatchNorm1d(n_hidden))\n",
        "# # model.add_module('do2', nn.Dropout(p=0.5))\n",
        "# model.add_module('dense4_relu', nn.ReLU())\n",
        "\n",
        "model.add_module('dense5_logits', nn.Linear(n_hidden, n_out))\n",
        "\n",
        "model.apply(init_weights)\n",
        "model.cuda()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (batch0): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dense1): Linear(in_features=30, out_features=200, bias=True)\n",
              "  (batch1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dense1_relu): ReLU()\n",
              "  (dense2): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (batch2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dense2_relu): ReLU()\n",
              "  (dense5_logits): Linear(in_features=200, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "1GoOqKAcn1nr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_loss(X_batch, y_batch):\n",
        "    X_batch = Variable(torch.FloatTensor(X_batch)).cuda()\n",
        "    y_batch = Variable(torch.LongTensor(y_batch)).cuda()\n",
        "    logits = model(X_batch)\n",
        "    return F.cross_entropy(logits, y_batch).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e7XT6zAFfZ-O",
        "colab_type": "code",
        "outputId": "2f578875-141a-48c5-e4c7-ff5b704d16f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# # example\n",
        "compute_loss(X_train[:5], y_train[:5])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3955, device='cuda:0', grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "10K7i0Btn1ny",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# An auxilary function that returns mini-batches for neural network training\n",
        "def iterate_minibatches(X, y, batchsize):\n",
        "    indices = np.random.permutation(np.arange(len(X)))\n",
        "    for start in range(0, len(indices), batchsize):\n",
        "        ix = indices[start: start + batchsize]\n",
        "        yield X[ix], y[ix]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ezmK9uvyn1n1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(model.parameters(),  lr=0.003, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='max', patience=10, factor=0.1)\n",
        "\n",
        "train_loss = []\n",
        "test_accuracy = []\n",
        "test_loss = []\n",
        "epoch_train_loss = []\n",
        "epoch_test_accuracy = []\n",
        "epoch_test_loss = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_UN9TaEMECxO",
        "colab_type": "code",
        "outputId": "5991f0aa-1551-4346-d053-0725726635b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4392
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "num_epochs = 50 # total amount of full passes over training data\n",
        "batch_size = 1000  # number of samples processed in one SGD iteration\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # In each epoch, we do a full pass over the training data:\n",
        "    start_time = time.time()\n",
        "    model.train(True) # enable dropout / batch_norm training behavior\n",
        "    for X_batch, y_batch in iterate_minibatches(X_train, y_train, batch_size):\n",
        "        # train on batch\n",
        "        loss = compute_loss(X_batch, y_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        train_loss.append(loss.data.cpu().numpy())\n",
        "        \n",
        "    # And a full pass over the validation data:\n",
        "    model.train(False) # disable dropout / use averages for batch_norm\n",
        "    for X_batch, y_batch in iterate_minibatches(X_test, y_test, batch_size):\n",
        "        logits = model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
        "        y_pred = logits.max(1)[1].data.cpu().numpy()\n",
        "        test_accuracy.append(np.mean(y_batch == y_pred))\n",
        "        test_loss.append(compute_loss(X_batch, y_batch).data.cpu().numpy())\n",
        "        \n",
        "    scheduler.step(np.mean(test_accuracy[-len(X_test) // batch_size :]))\n",
        "    \n",
        "    # Then we print the results for this epoch:\n",
        "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
        "        epoch + 1, num_epochs, time.time() - start_time))\n",
        "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
        "        np.mean(train_loss[-len(X_train) // batch_size :])))\n",
        "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
        "        np.mean(test_accuracy[-len(X_test) // batch_size :]) * 100))\n",
        "    print(\"  test loss       (in-iteration): \\t{:.6f}\\n\".format(\n",
        "        np.mean(test_loss[-len(X_test) // batch_size :])))\n",
        "    \n",
        "    epoch_train_loss.append(np.mean(train_loss[-len(X_train) // batch_size :]))\n",
        "    epoch_test_loss.append(np.mean(test_loss[-len(X_test) // batch_size :]))\n",
        "    epoch_test_accuracy.append(np.mean(test_accuracy[-len(X_test) // batch_size :]) * 100)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 of 50 took 0.311s\n",
            "  training loss (in-iteration): \t0.640852\n",
            "  validation accuracy: \t\t\t84.00 %\n",
            "  test loss       (in-iteration): \t0.381258\n",
            "\n",
            "Epoch 2 of 50 took 0.275s\n",
            "  training loss (in-iteration): \t0.360634\n",
            "  validation accuracy: \t\t\t85.04 %\n",
            "  test loss       (in-iteration): \t0.348073\n",
            "\n",
            "Epoch 3 of 50 took 0.249s\n",
            "  training loss (in-iteration): \t0.335727\n",
            "  validation accuracy: \t\t\t85.71 %\n",
            "  test loss       (in-iteration): \t0.335791\n",
            "\n",
            "Epoch 4 of 50 took 0.239s\n",
            "  training loss (in-iteration): \t0.321793\n",
            "  validation accuracy: \t\t\t84.95 %\n",
            "  test loss       (in-iteration): \t0.345634\n",
            "\n",
            "Epoch 5 of 50 took 0.241s\n",
            "  training loss (in-iteration): \t0.312299\n",
            "  validation accuracy: \t\t\t86.27 %\n",
            "  test loss       (in-iteration): \t0.329620\n",
            "\n",
            "Epoch 6 of 50 took 0.240s\n",
            "  training loss (in-iteration): \t0.303992\n",
            "  validation accuracy: \t\t\t87.12 %\n",
            "  test loss       (in-iteration): \t0.308322\n",
            "\n",
            "Epoch 7 of 50 took 0.240s\n",
            "  training loss (in-iteration): \t0.292543\n",
            "  validation accuracy: \t\t\t86.85 %\n",
            "  test loss       (in-iteration): \t0.310963\n",
            "\n",
            "Epoch 8 of 50 took 0.239s\n",
            "  training loss (in-iteration): \t0.289745\n",
            "  validation accuracy: \t\t\t86.09 %\n",
            "  test loss       (in-iteration): \t0.321012\n",
            "\n",
            "Epoch 9 of 50 took 0.242s\n",
            "  training loss (in-iteration): \t0.287982\n",
            "  validation accuracy: \t\t\t85.16 %\n",
            "  test loss       (in-iteration): \t0.348977\n",
            "\n",
            "Epoch 10 of 50 took 0.239s\n",
            "  training loss (in-iteration): \t0.277721\n",
            "  validation accuracy: \t\t\t87.58 %\n",
            "  test loss       (in-iteration): \t0.298001\n",
            "\n",
            "Epoch 11 of 50 took 0.248s\n",
            "  training loss (in-iteration): \t0.271826\n",
            "  validation accuracy: \t\t\t87.08 %\n",
            "  test loss       (in-iteration): \t0.300264\n",
            "\n",
            "Epoch 12 of 50 took 0.238s\n",
            "  training loss (in-iteration): \t0.271287\n",
            "  validation accuracy: \t\t\t87.14 %\n",
            "  test loss       (in-iteration): \t0.298041\n",
            "\n",
            "Epoch 13 of 50 took 0.243s\n",
            "  training loss (in-iteration): \t0.268873\n",
            "  validation accuracy: \t\t\t87.84 %\n",
            "  test loss       (in-iteration): \t0.286677\n",
            "\n",
            "Epoch 14 of 50 took 0.238s\n",
            "  training loss (in-iteration): \t0.266397\n",
            "  validation accuracy: \t\t\t87.34 %\n",
            "  test loss       (in-iteration): \t0.305130\n",
            "\n",
            "Epoch 15 of 50 took 0.238s\n",
            "  training loss (in-iteration): \t0.265665\n",
            "  validation accuracy: \t\t\t87.53 %\n",
            "  test loss       (in-iteration): \t0.297932\n",
            "\n",
            "Epoch 16 of 50 took 0.238s\n",
            "  training loss (in-iteration): \t0.266433\n",
            "  validation accuracy: \t\t\t87.11 %\n",
            "  test loss       (in-iteration): \t0.304669\n",
            "\n",
            "Epoch 17 of 50 took 0.243s\n",
            "  training loss (in-iteration): \t0.255924\n",
            "  validation accuracy: \t\t\t87.93 %\n",
            "  test loss       (in-iteration): \t0.287705\n",
            "\n",
            "Epoch 18 of 50 took 0.237s\n",
            "  training loss (in-iteration): \t0.254333\n",
            "  validation accuracy: \t\t\t87.88 %\n",
            "  test loss       (in-iteration): \t0.295170\n",
            "\n",
            "Epoch 19 of 50 took 0.240s\n",
            "  training loss (in-iteration): \t0.252429\n",
            "  validation accuracy: \t\t\t87.99 %\n",
            "  test loss       (in-iteration): \t0.283341\n",
            "\n",
            "Epoch 20 of 50 took 0.237s\n",
            "  training loss (in-iteration): \t0.246430\n",
            "  validation accuracy: \t\t\t88.37 %\n",
            "  test loss       (in-iteration): \t0.285291\n",
            "\n",
            "Epoch 21 of 50 took 0.243s\n",
            "  training loss (in-iteration): \t0.238884\n",
            "  validation accuracy: \t\t\t88.30 %\n",
            "  test loss       (in-iteration): \t0.282810\n",
            "\n",
            "Epoch 22 of 50 took 0.237s\n",
            "  training loss (in-iteration): \t0.234003\n",
            "  validation accuracy: \t\t\t88.20 %\n",
            "  test loss       (in-iteration): \t0.282821\n",
            "\n",
            "Epoch 23 of 50 took 0.241s\n",
            "  training loss (in-iteration): \t0.231523\n",
            "  validation accuracy: \t\t\t88.69 %\n",
            "  test loss       (in-iteration): \t0.270871\n",
            "\n",
            "Epoch 24 of 50 took 0.237s\n",
            "  training loss (in-iteration): \t0.230783\n",
            "  validation accuracy: \t\t\t88.27 %\n",
            "  test loss       (in-iteration): \t0.278235\n",
            "\n",
            "Epoch 25 of 50 took 0.237s\n",
            "  training loss (in-iteration): \t0.227776\n",
            "  validation accuracy: \t\t\t87.97 %\n",
            "  test loss       (in-iteration): \t0.289106\n",
            "\n",
            "Epoch 26 of 50 took 0.244s\n",
            "  training loss (in-iteration): \t0.228494\n",
            "  validation accuracy: \t\t\t89.14 %\n",
            "  test loss       (in-iteration): \t0.272425\n",
            "\n",
            "Epoch 27 of 50 took 0.237s\n",
            "  training loss (in-iteration): \t0.221105\n",
            "  validation accuracy: \t\t\t89.12 %\n",
            "  test loss       (in-iteration): \t0.263778\n",
            "\n",
            "Epoch 28 of 50 took 0.238s\n",
            "  training loss (in-iteration): \t0.219398\n",
            "  validation accuracy: \t\t\t88.79 %\n",
            "  test loss       (in-iteration): \t0.273574\n",
            "\n",
            "Epoch 29 of 50 took 0.238s\n",
            "  training loss (in-iteration): \t0.220032\n",
            "  validation accuracy: \t\t\t87.42 %\n",
            "  test loss       (in-iteration): \t0.306176\n",
            "\n",
            "Epoch 30 of 50 took 0.242s\n",
            "  training loss (in-iteration): \t0.216602\n",
            "  validation accuracy: \t\t\t88.81 %\n",
            "  test loss       (in-iteration): \t0.279584\n",
            "\n",
            "Epoch 31 of 50 took 0.239s\n",
            "  training loss (in-iteration): \t0.221299\n",
            "  validation accuracy: \t\t\t89.05 %\n",
            "  test loss       (in-iteration): \t0.269430\n",
            "\n",
            "Epoch 32 of 50 took 0.238s\n",
            "  training loss (in-iteration): \t0.214834\n",
            "  validation accuracy: \t\t\t89.61 %\n",
            "  test loss       (in-iteration): \t0.257851\n",
            "\n",
            "Epoch 33 of 50 took 0.239s\n",
            "  training loss (in-iteration): \t0.208526\n",
            "  validation accuracy: \t\t\t88.43 %\n",
            "  test loss       (in-iteration): \t0.279734\n",
            "\n",
            "Epoch 34 of 50 took 0.242s\n",
            "  training loss (in-iteration): \t0.210607\n",
            "  validation accuracy: \t\t\t89.04 %\n",
            "  test loss       (in-iteration): \t0.266055\n",
            "\n",
            "Epoch 35 of 50 took 0.241s\n",
            "  training loss (in-iteration): \t0.208160\n",
            "  validation accuracy: \t\t\t89.51 %\n",
            "  test loss       (in-iteration): \t0.257963\n",
            "\n",
            "Epoch 36 of 50 took 0.238s\n",
            "  training loss (in-iteration): \t0.209912\n",
            "  validation accuracy: \t\t\t89.08 %\n",
            "  test loss       (in-iteration): \t0.267074\n",
            "\n",
            "Epoch 37 of 50 took 0.239s\n",
            "  training loss (in-iteration): \t0.202545\n",
            "  validation accuracy: \t\t\t90.02 %\n",
            "  test loss       (in-iteration): \t0.255733\n",
            "\n",
            "Epoch 38 of 50 took 0.238s\n",
            "  training loss (in-iteration): \t0.204212\n",
            "  validation accuracy: \t\t\t88.44 %\n",
            "  test loss       (in-iteration): \t0.284522\n",
            "\n",
            "Epoch 39 of 50 took 0.243s\n",
            "  training loss (in-iteration): \t0.202610\n",
            "  validation accuracy: \t\t\t89.24 %\n",
            "  test loss       (in-iteration): \t0.272141\n",
            "\n",
            "Epoch 40 of 50 took 0.240s\n",
            "  training loss (in-iteration): \t0.198877\n",
            "  validation accuracy: \t\t\t89.43 %\n",
            "  test loss       (in-iteration): \t0.263834\n",
            "\n",
            "Epoch 41 of 50 took 0.239s\n",
            "  training loss (in-iteration): \t0.195066\n",
            "  validation accuracy: \t\t\t88.89 %\n",
            "  test loss       (in-iteration): \t0.267483\n",
            "\n",
            "Epoch 42 of 50 took 0.237s\n",
            "  training loss (in-iteration): \t0.192172\n",
            "  validation accuracy: \t\t\t89.69 %\n",
            "  test loss       (in-iteration): \t0.266922\n",
            "\n",
            "Epoch 43 of 50 took 0.245s\n",
            "  training loss (in-iteration): \t0.199035\n",
            "  validation accuracy: \t\t\t89.17 %\n",
            "  test loss       (in-iteration): \t0.270093\n",
            "\n",
            "Epoch 44 of 50 took 0.238s\n",
            "  training loss (in-iteration): \t0.193987\n",
            "  validation accuracy: \t\t\t89.21 %\n",
            "  test loss       (in-iteration): \t0.264887\n",
            "\n",
            "Epoch 45 of 50 took 0.239s\n",
            "  training loss (in-iteration): \t0.188549\n",
            "  validation accuracy: \t\t\t89.68 %\n",
            "  test loss       (in-iteration): \t0.255845\n",
            "\n",
            "Epoch 46 of 50 took 0.237s\n",
            "  training loss (in-iteration): \t0.190939\n",
            "  validation accuracy: \t\t\t90.15 %\n",
            "  test loss       (in-iteration): \t0.251564\n",
            "\n",
            "Epoch 47 of 50 took 0.241s\n",
            "  training loss (in-iteration): \t0.186216\n",
            "  validation accuracy: \t\t\t89.45 %\n",
            "  test loss       (in-iteration): \t0.265314\n",
            "\n",
            "Epoch 48 of 50 took 0.239s\n",
            "  training loss (in-iteration): \t0.185461\n",
            "  validation accuracy: \t\t\t89.34 %\n",
            "  test loss       (in-iteration): \t0.268072\n",
            "\n",
            "Epoch 49 of 50 took 0.240s\n",
            "  training loss (in-iteration): \t0.183595\n",
            "  validation accuracy: \t\t\t88.81 %\n",
            "  test loss       (in-iteration): \t0.274740\n",
            "\n",
            "Epoch 50 of 50 took 0.237s\n",
            "  training loss (in-iteration): \t0.182805\n",
            "  validation accuracy: \t\t\t88.91 %\n",
            "  test loss       (in-iteration): \t0.274043\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mFil60I_nmT2",
        "colab_type": "code",
        "outputId": "4f0e31b7-8f09-462d-e1d6-9cda61a48561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(epoch_train_loss)\n",
        "plt.plot(epoch_test_loss)\n",
        "plt.title('logloss')\n",
        "# plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "fig.show()\n",
        "# fig.savefig('loss' + postfix + '.pdf')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEWCAYAAACdaNcBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "kOzv4wTxoKBE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logits = model(Variable(torch.FloatTensor(X_test)).cuda())\n",
        "test_proba = F.softmax(logits.cpu()).data.numpy()[:, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y5cn8qHZn-ca",
        "colab_type": "code",
        "outputId": "000fd290-f55e-4bbf-994e-406835bb9583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "print(f'ROC AUC = {roc_auc_score(y_test, test_proba)}')\n",
        "print(f'log loss = {log_loss(y_test,test_proba)}')\n",
        "print(f'Matthews correlation coefficient = {matthews_corrcoef(y_test, test_proba > 0.5):.3f}')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC AUC = 0.9650194384244923\n",
            "log loss = 0.24553227996702148\n",
            "Matthews correlation coefficient = 0.807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3NFjYIWGQpAU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### keras net"
      ]
    },
    {
      "metadata": {
        "id": "778eZAZlJ4W0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c2da3d8-bd65-43cf-c449-5b6a72b1a68a"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
        "from keras import optimizers, losses, metrics, initializers\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "import keras.backend as K\n",
        "\n",
        "import tensorflow as tf \n",
        "tf.set_random_seed(123)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ja9kg0ahNUU3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "AMS_metric_cut = 0.2#0.99822"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IaHAnbAazzjO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def AMS_cut_tf(cut, prediction, true_labels, sig_sum_w = sig_sum_w, bkgr_sum_w = bkgr_sum_w, br = 0.00000001): #, prediction = prediction_test, true_labels = y_test\n",
        "\n",
        "    s = K.all(K.stack([K.greater(prediction, cut[0]) , (K.equal(true_labels, 1))], axis=0), axis=0)\n",
        "    b = K.all(K.stack([K.greater(prediction, cut[0]) , (K.equal(true_labels, 0))], axis=0), axis=0)\n",
        "    s = K.cast(s, dtype='float32')\n",
        "    b = K.cast(b, dtype='float32')\n",
        "    \n",
        "    \n",
        "    s_weight = K.constant(sig_sum_w)  / K.sum(K.cast(K.equal(true_labels, 1), dtype='float32'))\n",
        "    b_weight = K.constant(bkgr_sum_w) / K.sum(K.cast(K.equal(true_labels, 0), dtype='float32'))\n",
        "    \n",
        "    s = s * s_weight; b = b * b_weight\n",
        "    s = K.sum(s); b = K.sum(b)\n",
        "#     print(s)\n",
        "#     print(b)\n",
        "    radicand = 2 *( (s+b+br) * K.log (1.0 + s/(b+br)) - s)\n",
        "#     if radicand < 0:\n",
        "#         print('radicand is negative. Exiting')\n",
        "#         return -1\n",
        "#     else:\n",
        "    ams = K.switch(K.greater(s+b, K.constant(10)), K.sqrt(radicand), K.constant(0))\n",
        "    return ams\n",
        "\n",
        "def AMS_eval_tf(y_true, y_pred):\n",
        "    return -AMS_cut_tf([AMS_metric_cut], sig_sum_w = sig_sum_w, bkgr_sum_w = bkgr_sum_w, prediction = y_pred, true_labels = y_true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9vPtcNdshibR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def binary_focal_loss(y_true, y_pred):\n",
        "#     \"\"\"\n",
        "#     Binary form of focal loss.\n",
        "#       FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n",
        "#       where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
        "#     References:\n",
        "#         https://arxiv.org/pdf/1708.02002.pdf\n",
        "#     Usage:\n",
        "#      model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
        "#     \"\"\"\n",
        "#     def binary_focal_loss_fixed(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    :param y_true: A tensor of the same shape as `y_pred`\n",
        "    :param y_pred:  A tensor resulting from a sigmoid\n",
        "    :return: Output tensor.\n",
        "    \"\"\"\n",
        "    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "\n",
        "    epsilon = K.epsilon()\n",
        "    # clip to prevent NaN's and Inf's\n",
        "    pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n",
        "    pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n",
        "    \n",
        "    alpha = 0.001\n",
        "    gamma = 2.\n",
        "    \n",
        "    return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \\\n",
        "           -K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wDPVzLyQQqvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "06964521-ad6e-443b-af94-71205ae34d3e"
      },
      "cell_type": "code",
      "source": [
        "_lr = 0.003\n",
        "optim = optimizers.Adam(lr=_lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, amsgrad=False)\n",
        "loss  = losses.binary_crossentropy\n",
        "w_init = initializers.he_normal(seed=123)\n",
        "bias_init = initializers.Constant(value=0.01)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=_lr*0.01)\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=1e-2, patience=30, verbose=0, mode='min', baseline=None, restore_best_weights=False)\n",
        "\n",
        "num_epochs = 1000\n",
        "batch_size = 1000"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HPibiNHQSjZm",
        "colab_type": "code",
        "outputId": "8ae38546-7fdd-4aa4-d73f-3e2a62741ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1874
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-05, center=True, scale=True, \n",
        "                             beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "          \n",
        "model.add(Dense(200, input_dim=X_train.shape[1], kernel_initializer=w_init, bias_initializer=bias_init))          \n",
        "model.add(BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-05, center=True, scale=True, \n",
        "                             beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(200,kernel_initializer=w_init, bias_initializer=bias_init))       \n",
        "model.add(BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-05, center=True, scale=True, \n",
        "                             beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# model.add(Dense(200,kernel_initializer=w_init, bias_initializer=bias_init))\n",
        "# model.add(BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-05, center=True, scale=True, \n",
        "#                              beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "# model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "          \n",
        "model.compile(loss=loss, #binary_focal_loss\n",
        "              optimizer=optim,\n",
        "              metrics=[]) #, 'binary_crossentropy', AMS_eval_tf, 'acc', \n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "          epochs=num_epochs,\n",
        "          callbacks=[reduce_lr, es],\n",
        "          batch_size=batch_size,\n",
        "          validation_data=(X_test, y_test)\n",
        "         )\n",
        "\n",
        "score = model.evaluate(X_val, y_val, batch_size=batch_size)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 44652 samples, validate on 14885 samples\n",
            "Epoch 1/1000\n",
            "44652/44652 [==============================] - 7s 148us/step - loss: 0.3832 - val_loss: 0.3322\n",
            "Epoch 2/1000\n",
            "44652/44652 [==============================] - 1s 12us/step - loss: 0.3241 - val_loss: 0.3185\n",
            "Epoch 3/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.3109 - val_loss: 0.3125\n",
            "Epoch 4/1000\n",
            "44652/44652 [==============================] - 1s 12us/step - loss: 0.3022 - val_loss: 0.3107\n",
            "Epoch 5/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.2929 - val_loss: 0.2997\n",
            "Epoch 6/1000\n",
            "44652/44652 [==============================] - 1s 12us/step - loss: 0.2808 - val_loss: 0.2874\n",
            "Epoch 7/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.2728 - val_loss: 0.2817\n",
            "Epoch 8/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.2659 - val_loss: 0.2779\n",
            "Epoch 9/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.2598 - val_loss: 0.2761\n",
            "Epoch 10/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.2518 - val_loss: 0.2650\n",
            "Epoch 11/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.2457 - val_loss: 0.2601\n",
            "Epoch 12/1000\n",
            "44652/44652 [==============================] - 1s 12us/step - loss: 0.2397 - val_loss: 0.2715\n",
            "Epoch 13/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.2378 - val_loss: 0.2549\n",
            "Epoch 14/1000\n",
            "44652/44652 [==============================] - 1s 12us/step - loss: 0.2321 - val_loss: 0.2556\n",
            "Epoch 15/1000\n",
            "44652/44652 [==============================] - 0s 11us/step - loss: 0.2260 - val_loss: 0.2479\n",
            "Epoch 16/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.2245 - val_loss: 0.2494\n",
            "Epoch 17/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.2187 - val_loss: 0.2469\n",
            "Epoch 18/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.2157 - val_loss: 0.2575\n",
            "Epoch 19/1000\n",
            "44652/44652 [==============================] - 0s 11us/step - loss: 0.2162 - val_loss: 0.2514\n",
            "Epoch 20/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.2114 - val_loss: 0.2433\n",
            "Epoch 21/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.2093 - val_loss: 0.2396\n",
            "Epoch 22/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.2035 - val_loss: 0.2687\n",
            "Epoch 23/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.2053 - val_loss: 0.2425\n",
            "Epoch 24/1000\n",
            "44652/44652 [==============================] - 1s 12us/step - loss: 0.1985 - val_loss: 0.2508\n",
            "Epoch 25/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.1954 - val_loss: 0.2536\n",
            "Epoch 26/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.1957 - val_loss: 0.2469\n",
            "Epoch 27/1000\n",
            "44652/44652 [==============================] - 0s 11us/step - loss: 0.1932 - val_loss: 0.2518\n",
            "Epoch 28/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.1915 - val_loss: 0.2437\n",
            "Epoch 29/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.1865 - val_loss: 0.2442\n",
            "Epoch 30/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.1841 - val_loss: 0.2519\n",
            "Epoch 31/1000\n",
            "44652/44652 [==============================] - 0s 11us/step - loss: 0.1824 - val_loss: 0.2451\n",
            "Epoch 32/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.1646 - val_loss: 0.2342\n",
            "Epoch 33/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.1604 - val_loss: 0.2351\n",
            "Epoch 34/1000\n",
            "44652/44652 [==============================] - 1s 12us/step - loss: 0.1574 - val_loss: 0.2350\n",
            "Epoch 35/1000\n",
            "44652/44652 [==============================] - 0s 11us/step - loss: 0.1565 - val_loss: 0.2392\n",
            "Epoch 36/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.1560 - val_loss: 0.2341\n",
            "Epoch 37/1000\n",
            "44652/44652 [==============================] - 0s 11us/step - loss: 0.1555 - val_loss: 0.2352\n",
            "Epoch 38/1000\n",
            "44652/44652 [==============================] - 1s 12us/step - loss: 0.1543 - val_loss: 0.2370\n",
            "Epoch 39/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.1531 - val_loss: 0.2374\n",
            "Epoch 40/1000\n",
            "44652/44652 [==============================] - 1s 12us/step - loss: 0.1523 - val_loss: 0.2360\n",
            "Epoch 41/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.1524 - val_loss: 0.2384\n",
            "Epoch 42/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.1513 - val_loss: 0.2367\n",
            "Epoch 43/1000\n",
            "44652/44652 [==============================] - 0s 11us/step - loss: 0.1509 - val_loss: 0.2400\n",
            "Epoch 44/1000\n",
            "44652/44652 [==============================] - 0s 11us/step - loss: 0.1499 - val_loss: 0.2353\n",
            "Epoch 45/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.1495 - val_loss: 0.2425\n",
            "Epoch 46/1000\n",
            "44652/44652 [==============================] - 0s 11us/step - loss: 0.1491 - val_loss: 0.2440\n",
            "Epoch 47/1000\n",
            "44652/44652 [==============================] - 0s 11us/step - loss: 0.1463 - val_loss: 0.2386\n",
            "Epoch 48/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.1453 - val_loss: 0.2427\n",
            "Epoch 49/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.1456 - val_loss: 0.2409\n",
            "Epoch 50/1000\n",
            "44652/44652 [==============================] - 1s 11us/step - loss: 0.1451 - val_loss: 0.2384\n",
            "14885/14885 [==============================] - 0s 3us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FI-qJm5rdGj5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b2b16450-9a04-4169-ef8e-e615f42ec5e5"
      },
      "cell_type": "code",
      "source": [
        "test_proba = model.predict(X_test)[:, 0]\n",
        "\n",
        "print(f'ROC AUC = {roc_auc_score(y_test, test_proba)}')\n",
        "print(f'log loss = {log_loss(y_test,test_proba)}')\n",
        "print(f'Matthews correlation coefficient = {matthews_corrcoef(y_test, test_proba > 0.5):.3f}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC AUC = 0.965874092895489\n",
            "log loss = 0.23844307306617965\n",
            "Matthews correlation coefficient = 0.810\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "24nCVVaCClCn",
        "colab_type": "code",
        "outputId": "a4e84098-0427-4029-afcb-3afd691bbeaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n",
        "\n",
        "# postfix = 'CEL'#'_FL_p1'\n",
        "# # summarize history for accuracy\n",
        "# fig = plt.figure()\n",
        "# plt.plot(history.history['acc'])\n",
        "# plt.plot(history.history['val_acc'])\n",
        "# plt.title('accuracy')\n",
        "# # plt.ylabel('accuracy')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper right')\n",
        "# fig.show()\n",
        "# # fig.savefig('acc' + postfix + '.pdf')\n",
        "\n",
        "# summarize history for loss\n",
        "fig = plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('logloss')\n",
        "# plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "fig.show()\n",
        "# fig.savefig('loss' + postfix + '.pdf')\n",
        "\n",
        "# # summarize history for AMS\n",
        "# fig = plt.figure()\n",
        "# plt.plot(history.history['AMS_eval_tf'])\n",
        "# plt.plot(history.history['val_AMS_eval_tf'])\n",
        "# plt.title('AMS')\n",
        "# # plt.ylabel('AMS')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper right')\n",
        "# # plt.ylim((-2,-1.5))\n",
        "# fig.show()\n",
        "# # fig.savefig('AMS' + postfix + '.pdf')\n",
        "\n",
        "# learning rate\n",
        "fig = plt.figure()\n",
        "plt.plot(history.history['lr'])\n",
        "plt.title('learning rate')\n",
        "# plt.ylabel('LR')\n",
        "plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper right')\n",
        "fig.show()\n",
        "# fig.savefig('LR' + postfix + '.pdf')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'loss', 'lr'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSObK0ss2GwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "uctm1ckSFYJZ",
        "colab_type": "code",
        "outputId": "74232170-86e9-4915-caaf-362a66ee200b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_val, y_val, batch_size=batch_size)\n",
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14885/14885 [==============================] - 0s 4us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[149.83467346539945, 0.8614040930518617, 1.073493946307371]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "metadata": {
        "id": "JXrA8QEKosOE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### **AMS opt**"
      ]
    },
    {
      "metadata": {
        "id": "-Pj8eksrKYgh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sig_sum_w = 100; bkgr_sum_w = 100000; "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "givyVTMezj5M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def AMS_cut(cut, prediction, true_labels, sig_sum_w = sig_sum_w, bkgr_sum_w = bkgr_sum_w, br = 0.00000001): #, prediction = prediction_test, true_labels = y_test\n",
        "\n",
        "    s = np.array((prediction > cut[0]) * (true_labels == 1), dtype='float32')\n",
        "    b = np.array((prediction > cut[0]) * (true_labels == 0), dtype='float32')\n",
        "\n",
        "    s_weight = sig_sum_w  / np.argwhere(true_labels == 1).shape[0]\n",
        "    b_weight = bkgr_sum_w / np.argwhere(true_labels == 0).shape[0]\n",
        "\n",
        "    s *= s_weight; b *= b_weight\n",
        "    s = sum(s); b = sum(b)\n",
        "#     print(s_weight, b_weight)\n",
        "#     print(s)\n",
        "#     print(b)\n",
        "    radicand = 2 *( (s+b+br) * math.log (1.0 + s/(b+br)) - s)\n",
        "#     if radicand < 0:\n",
        "#         print('radicand is negative. Exiting')\n",
        "#         return -1\n",
        "#     else:\n",
        "    ams = math.sqrt(radicand) if s+b > 10 else 0\n",
        "    return ams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GYI0BiRAooMg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def optimize_me(domain, prediction, true_labels, sig_sum_w=sig_sum_w, bkgr_sum_w = bkgr_sum_w, n_iter = 10):\n",
        "    optimizer = BayesianOptimization(f= lambda x: AMS_cut(x, prediction = prediction, true_labels = true_labels, sig_sum_w = sig_sum_w, bkgr_sum_w = bkgr_sum_w), \n",
        "    #                                  some_metric_cut,\n",
        "                                     domain=domain,\n",
        "                                     model_type='GP',\n",
        "                                     acquisition_type ='MPI',\n",
        "    #                                  n_samples = 5,\n",
        "                                     evaluator_type = 'local_penalization',\n",
        "                                     initial_design_numdata = 30,\n",
        "                                     initial_design_type='sobol',\n",
        "                                     batch_size = 1,\n",
        "                                     acquisition_jitter = 0.005,\n",
        "                                     exact_feval = True, \n",
        "                                     maximize = True,\n",
        "                                     num_cores = 2)\n",
        "\n",
        "    # Only 20 iterations because we have 5 initial random points\n",
        "\n",
        "    # optimizer.run_optimization(max_iter=5, max_time=180, eps=1e-6, verbosity=True, context={'n_estimators':10})\n",
        "    optimizer.run_optimization(max_iter=n_iter, max_time=1800, eps=1e-6, verbosity=True) \n",
        "    return optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2WZz2Glao-3A",
        "colab_type": "code",
        "outputId": "6ff02476-8969-4c56-bc9a-52c8c5b4d567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "cell_type": "code",
      "source": [
        "domain = [\n",
        "    {'name': 'cut', 'type': 'continuous', 'domain': (0.7, 0.999)}\n",
        "  ]\n",
        "\n",
        "optimizer = optimize_me(domain, test_proba, y_test, n_iter = 20)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num acquisition: 1, time elapsed: 0.49s\n",
            "num acquisition: 2, time elapsed: 0.97s\n",
            "num acquisition: 3, time elapsed: 1.50s\n",
            "num acquisition: 4, time elapsed: 1.97s\n",
            "num acquisition: 5, time elapsed: 2.46s\n",
            "num acquisition: 6, time elapsed: 2.93s\n",
            "num acquisition: 7, time elapsed: 3.46s\n",
            "num acquisition: 8, time elapsed: 3.90s\n",
            "num acquisition: 9, time elapsed: 4.31s\n",
            "num acquisition: 10, time elapsed: 4.79s\n",
            "num acquisition: 11, time elapsed: 5.32s\n",
            "num acquisition: 12, time elapsed: 5.73s\n",
            "num acquisition: 13, time elapsed: 6.14s\n",
            "num acquisition: 14, time elapsed: 6.56s\n",
            "num acquisition: 15, time elapsed: 7.03s\n",
            "num acquisition: 16, time elapsed: 7.78s\n",
            "num acquisition: 17, time elapsed: 8.46s\n",
            "num acquisition: 18, time elapsed: 9.27s\n",
            "num acquisition: 19, time elapsed: 10.00s\n",
            "num acquisition: 20, time elapsed: 10.62s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Loh4FG7010B",
        "colab_type": "code",
        "outputId": "051ef7c0-acd1-4a71-94b1-730544fa0cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "# y_rs = np.maximum.accumulate(rs.cv_results_['mean_test_score'])\n",
        "y_bo = np.maximum.accumulate(-optimizer.Y).ravel()\n",
        "\n",
        "# print(f'Baseline neg. MSE = {baseline:.2f}')\n",
        "# print(f'Random search = {y_rs[-1]:.2f}')\n",
        "print(f'Bayesian optimization score = {y_bo[-1]:.2f}')\n",
        "\n",
        "# plt.plot(y_rs, 'ro-', label='Random search')\n",
        "plt.plot(y_bo, 'bo-', label='Bayesian optimization')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Neg. Loss')\n",
        "# plt.ylim(-5000, -3000)\n",
        "plt.title('Value of the best sampled CV score');\n",
        "plt.legend();\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bayesian optimization score = 1.84\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEFJQUREEpQUREQkQUlBREQS/g9EuR5+Ufbk0wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ODpF1X5S07pW",
        "colab_type": "code",
        "outputId": "b1f621b8-2ca2-47da-e670-d59abfe15277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(optimizer.X, -optimizer.Y, 'bo')\n",
        "plt.xlim(0.7, 1.)\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFiL8AaCFCH8AaKH/B+XP4yjNPUEJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "30w7PH3M3paB",
        "colab_type": "code",
        "outputId": "39856170-1ee3-43fb-8ef5-62877e5db0ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(f'best signif. = {max(-optimizer.Y_best)} for cut = {optimizer.x_opt[0]:.5f}')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best signif. = 1.8399509662674232 for cut = 0.99705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CddMb-CA2Dyh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_f= lambda x: AMS_cut(x, prediction = test_proba, true_labels = y_test, sig_sum_w = sig_sum_w, bkgr_sum_w = bkgr_sum_w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a_0V1m5h2JDg",
        "colab_type": "code",
        "outputId": "cac8fcf9-6c50-4c3f-a417-638532e7c2cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "_s = (test_proba > 0.997) & (y_test == 1)\n",
        "_b = (test_proba > 0.997) & (y_test == 0)\n",
        "\n",
        "s_weight = sig_sum_w  / np.argwhere(y_test == 1).shape[0]\n",
        "b_weight = bkgr_sum_w / np.argwhere(y_test == 0).shape[0]\n",
        "_s = np.array(_s, dtype='int') * s_weight; _b = np.array(_b, dtype='int') * b_weight\n",
        "\n",
        "sum(_s), sum(_b)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19.779629131953776, 147.78986967620585)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "PaXzuxEd4Qhe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}